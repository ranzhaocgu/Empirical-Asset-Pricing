\documentclass[11pt,reqno,final]{amsart}
\usepackage[font=small,margin=10pt,labelfont={bf},labelsep={space}]{caption}
\usepackage{subfig}
\usepackage{wrapfig}
\usepackage{amsmath, amssymb, epsfig}
\usepackage[scaled]{helvet} % I like Helvetica for sf
\usepackage{fourier}
\usepackage{bm}
\usepackage{color}
\usepackage{fullpage} 	% Fullpage package
%\usepackage{cite}
%\usepackage{citesort}
\newcommand{\notate}[1]{\textcolor{red}{\textbf{[#1]}}}
%\input{macros}


\newcommand{\tasos}{\text{TASOS}}
%Results
%Shortcuts
\newcommand{\hide}[1]{}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
%\newcommand{\A}{\mathbf{A}}
\newcommand{\bi}{\mathbf{b}}
\newcommand{\ro}{\mathbf{r}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\zero}{\mathbf{0}}
\newcommand{\ep}{\epsilon}
\newcommand{\de}{\delta}
\newcommand{\defby}{\overset{\mathrm{\scriptscriptstyle{def}}}{=}}
\newcommand{\bigO}{\mathrm{O}}
\DeclareMathOperator*{\argmin}{arg min}
\DeclareMathOperator*{\argmax}{arg max}
%************************************
%************************************
% The macros below are due to Tassos Zouzias
%************************************
%************************************

\newcommand{\eps}{\varepsilon}


\newcommand{\Prob}[1]{\ensuremath{\mathbb{P}\left(#1\right)}}

\newcommand{\OO}{\mathcal{O}}
\newcommand{\vol}[1]{\text{vol}(#1)}
\newcommand{\tr}{\rm{Tr}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\reals}{\mathbb{R}}


\newcommand{\e}{\ensuremath{{\rm e}}}
\DeclareMathOperator{\EE}{\mathbb{E}}
% Variance
\newcommand{\var}[1]{\ensuremath{\mathrm{Var}(#1)}}
% Pseudo-inverse of a matrix
\newcommand{\pinv}[1]{ {#1}^\dagger}
\newcommand{\norm}[1]{\ensuremath{\left\|#1\right\|_2}}
\newcommand{\pnorm}[1]{\ensuremath{\left\|#1\right\|_p}}
\newcommand{\qnorm}[1]{\ensuremath{\left\|#1\right\|_q}}
\newcommand{\infnorm}[1]{\ensuremath{\left\|#1\right\|_\infty}}
\newcommand{\onenorm}[1]{\ensuremath{\left\|#1\right\|_1}}
\newcommand{\frobnorm}[1]{\ensuremath{\left\|#1\right\|_{\text{\rm F}}}}
% Stable rank of a matrix
\newcommand{\sr}[1]{\ensuremath{\mathrm{\textbf{\footnotesize sr}}\left(#1\right)}}
% Trace of a matrix.
\newcommand{\trace}[1]{\ensuremath{\mathrm{\textbf{tr}}\left(#1\right)}}
%\DeclareMathOperator{\trace}{trace}
% Rank of a matrix
\newcommand{\rank}[1]{\ensuremath{\mathrm{\textbf{{\footnotesize rank}}}\left(#1\right)}}
% Kernel of a matrix
%\newcommand{\ker}[1]{\ensuremath{\mathrm{\textbf{ker}}\left(#1\right)}}
% Image of a matrix
\newcommand{\im}[1]{\ensuremath{\mathrm{\textbf{Im}}\left(#1\right)}}

% Condition number of a matrix
\newcommand{\cond}[1]{\ensuremath{\mathrm{\text{cond}}\left(#1\right)}}

\newcommand{\expm}[1]{\ensuremath{\mathrm{\textbf{\footnotesize exp}}\left[#1\right]}}
\newcommand{\coshm}[1]{\ensuremath{\mathrm{\textbf{\footnotesize cosh}}\left[#1\right]}}
\newcommand{\detm}[1]{\ensuremath{\mathrm{\textbf{det}}\left(#1\right)}}
\newcommand{\sign}[1]{\ensuremath{\mathrm{\textbf{sign}}\left(#1\right)}}


% # of non-zero entries of a matrix
\newcommand{\nnz}[1]{\ensuremath{\mathrm{\textbf{\footnotesize nnz}}\left(#1\right)}}

% Diagonal Matrix
\newcommand{\diag}[1]{\ensuremath{\mathrm{\textbf{diag}}\left(#1\right)}}
% Polylog(n)
\newcommand{\polylog}[1]{\ensuremath{\mathrm{polylog}\left(#1\right)}}

\newcommand{\old}{\text{old}}
\newcommand{\new}{\text{new}}
\newcommand{\ravg}{\text{R}_{\text{avg}}}
\newcommand{\cavg}{\text{C}_{\text{avg}}}
%\newcommand{\cavg}[1]{\text{C}_{\text{avg}}(#1)}


%%% Vector and matrix operators

\newcommand{\vct}[1]{\bm{#1}}
\newcommand{\mtx}[1]{\bm{#1}}

\newcommand{\ip}[2]{\left\langle {#1},\ {#2} \right\rangle}
\newcommand{\mip}[2]{ {#1}\bullet {#2}}

\newcommand{\ignore}[1]{}

\newcommand{\Id}{\mathbf{I}}
\newcommand{\J}{\mathbf{J}}
\newcommand{\onemtx}{\bm{1}}
%\newcommand{\zeromtx}{\bm{0}}
\newcommand{\zeromtx}{\mathbf{0}}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\mat}[1]{ {\ensuremath{\mtx{#1} }}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\def\gammab{{\bm{\gamma}}}
\def\kappab{{\bm{\kappa}}}
\def\sig{{\bm{\Sigma}}}
\def\sigplus{{\bm{\Sigma}^{+}}}
\def\siginv{{\bm{\Sigma}^{-1}}}
\def\bet{{\bm{\beta}}}
\def\one{{\bm{1}}}
\def\exp{\hbox{\rm exp}}
\def\col{\hbox{\rm col}}
\def\ker{\hbox{\rm ker}}
\def\ahat{{\hat\a}}
\def\p{{\mathbf p}}
\def\e{{\mathbf e}}
\def\q{{\mathbf q}}
\def\rb{{\mathbf r}}
\def\s{{\mathbf s}}
\def\u{{\mathbf u}}
\def\v{{\mathbf v}}
\def\d{{\mathbf \delta}}
\def\xhat{{\hat\x}}
\def\yhat{{\hat\y}}
\def\A{\matA}
\def\B{\matB}
\def\C{\matC}
\def\Ahat{\hat\matA}
\def\Atilde{\tilde\matA}
\def\Btilde{\tilde\matB}
\def\Stilde{\tilde\matS}
\def\Utilde{\tilde\matU}
\def\Vtilde{\tilde\matV}
\def\G{{\cl G}}
\def\hset{{\cl H}}
\def\Q{{\bm{Q}}}
\def\U{{\bm{U}}}
\def\V{{\bm{V}}}
\def\win{\hat{\w}}
\def\wopt{\w^*}
\def\matAhat{\hat\mat{A}}
\def\matA{\mat{A}}
\def\matB{\mat{B}}
\def\matC{\mat{C}}
\def\matD{\mat{D}}
\def\matE{\mat{E}}
\def\matH{\mat{H}}
\def\matI{\mat{I}}
\def\matM{\mat{M}}
\def\matP{\mat{P}}
\def\matQ{\mat{Q}}
\def\matR{\mat{R}}
\def\matL{\mat{L}}

\def\matS{\mat{S}}
\def\matT{\mat{T}}
\def\matU{\mat{U}}
\def\matV{\mat{V}}
\def\matW{\mat{W}}
\def\matX{\mat{X}}
\def\matY{\mat{Y}}
\def\matZ{\mat{Z}}
\def\matSig{\mat{\Sigma}}
\def\matOmega{\mat{\Omega}}
\def\matGam{\mat{\Gamma}}
\def\matTheta{\mat{\Theta}}
\def\w{{\mathbf{w}}}
\def\ein{{\cl E_{\text{\rm in}}}}
\def\eout{{\cl E}}
\def\scl{{\textsc{l}}}
\def\scu{{\textsc{u}}}
\def\phiu{{\overline{\phi}}}
\def\psiu{{\overline{\psi}}}
\def\phil{{\underbar{\math{\phi}}}}
\newcommand\remove[1]{}


\newcommand{\vecb}{{\vct{b} }}
\newcommand{\bc}{{\vecb_{\mathcal{R}(\matA)^\bot } }}
\newcommand{\br}{{\vecb_{\mathcal{R}(\matA) } }}

% Least squares solution of Ax = b
\def\xls{\x_{\text{\tiny LS}}}

% For rows and columns of a matrix A
\newcommand{\ar}[1]{ \matA^{(#1)}}
\newcommand{\ac}[1]{ \matA_{(#1)}}

\newcommand{\colspan}[1]{\mathcal{R}(#1)}

\usepackage{palatino}

%---------------------Listings--------------------%
\usepackage{listings}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{ %
  language=Octave,                % the language of the code
  basicstyle=\footnotesize,           % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=2,                   % the step between two line-numbers. If it's 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},      % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  title=\lstname,                   % show the filename of files included with \lstinputlisting;
                                  % also try caption instead of title
  keywordstyle=\color{blue},          % keyword style
  commentstyle=\color{dkgreen},       % comment style
  stringstyle=\color{mauve},         % string literal style
  escapeinside={\%*}{*)},            % if you want to add LaTeX within your code
  morekeywords={*,...}               % if you want to add more keywords to the set
}
%-------------------------------------------------%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{hyperref}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{tabularx,ragged2e,booktabs,caption}

% Place this after the backref command
\usepackage{algorithmicx}
\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}

\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{question}{Question}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{example}{Example}
%\newtheorem{algorithm}{Algorithm}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{remark}{Remark}
\newtheorem{problem}{Problem}

%-------------------------------------------------%


%%%%%%%%%%%%%%
% Document
%%%%%%%%%%%%%%


\title{Calibration on Merton Jump Diffusion Using Bayesian MCMC Method}
\author{Ran Zhao}
\thanks{}
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

\end{abstract}

\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
\section{Introduction}
Advances in computing powers and numerical methods have largely improve the capability of solving econometric and statistical models using computational intense methods, includes Markov Chain Monte Carlo (MCMC) method. Especially in dynamic asset pricing models, the MCMC method is widely utilized to extracting information about latent state variables (such as implied volatility), structural parameters and market prices of risk (volatility or jump risks) from observed prices or market quotes. The Bayesian inference is to obtain the distribution of parameter set, $\Theta$, and (optional) state variables, $X$, conditioning on the observed prices, $Y$. That is, the posterior distribution, $p(\Theta, X|Y)$ is vital to the parameters estimation and their statistical inference.

Consider a stochastic process $\{X_t\}$, where each $X_t$ assumes value in space $\Omega$. Then the process $\{X_t\}$ is a Markov process if given the value of $X_t$, the values of $X_{t+h}$, $h>0$, do not depend on the values $X_s$, $s<t$. That is, $\{X_t\}$ is a Markov process if its conditioanl distribution function satisfies

$$
\mathbb{P}(X_{t+h}|X_s, s \leq t) = \mathbb{P}(X_{t+h}|X_t), \quad h>0.
$$

In continuous-time asset pricing models, MCMC that explore their posterior distributions samples from high-dimensional and sophisticated distributions by generating Markon process over $(\Theta,X)$, $\{\Theta^{(g)}, X^{(g)}\}_{g=1}^{G}$. And the equilibrium distribution of $(\Theta,X)$ is $p(\Theta, X|Y)$. Then Monte Carlo methods use these samples for statistical inference on parameters and states.

However, $p(\Theta, X|Y)$ in continuous-time asset pricing models is usually not easy to obtain. Johannes and Polson~\cite{JP02} listed the reasons for this difficulty, which summarize as
\begin{enumerate}
    \item market prices are observed discretely (e.g. on daily basis) while the asset pricing models specify the prices and states to evolve continuously;
    \item the state variables are latent based on researcher's perspective but not observable on the market;
    \item $p(\Theta, X|Y)$ is usually in high dimension, causing common sampling method to fail;
    \item the transition distributions for prices and states of the asset pricing model are non-normal and non-standard, complication the standard estimation methods such as MLE and GMM;
    \item the parameters of the asset pricing models are usually nonlinear and non-analytic form as the implicit solution to a stochastic differential equations.
\end{enumerate}

A typical application of MCMC technique in asset pricing model is Jacquier, Polson and Rossi~\cite{JPR94}, where a cyclic Metropolis algorithm is used to construct a Markov-chain simulation on stochastic volatility model.


\section{Model Specification}
\subsection{Geometric Brownian Motion (Black-Scholes)}
The baseline model selected for fitting the underlying stock returns is Black-Scholes model~\cite{BS73}, where the stock price dynamic, $S_t$, follows Geometric Brownian Motion
$$
d S_t = \left(\mu+\frac{1}{2}\sigma^2\right) S_t dt + \sigma S_t dW_t
$$
where $\mu$ is the drift term and $\sigma$ is the volatility. $W_t$ is the Wiener process. This model assumes the stock returns follow a random walk. In reality, the S\&P500 index level and returns on daily basis are plotted in Figure~\ref{plot_spx}.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{spx_index_return.eps}
  \caption{The SPX index levels and return on daily basis. Time period is from 1954 to 2015.}\label{plot_spx}
\end{figure}

In discrete time equally space, the model has close-form solution for the return
$$
Y_t = \log(S_t / S_{t-1}) = \mu + \sigma \epsilon_t
$$
where $\epsilon_t \sim N(0,1)$. We have $\Theta = (\mu, \sigma^2)$. There is no latent variable, which implies the posterior to be $p(\Theta|Y) = p(\mu,\sigma|Y)$.

Using Hammersley-Clifford theorem~\cite{CH70}, $p(\mu|\sigma^2,Y)$ and $p(\sigma^2|\mu,Y)$ are complete conditionals to the posterior. Assuming independent priors on $\mu$ and $\sigma^2$, Bayes rule implies that
\begin{eqnarray*}
p(\mu|\sigma^2, Y) &\propto& p(Y|\mu,\sigma^2)(\mu) \\
p(\sigma^2|\mu, Y) &\propto& p(Y|\mu,\sigma^2)(\sigma^2) \\
p(Y|\mu,\sigma^2) &=& \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right)^T \exp\left( -\frac{1}{2} \sum_{t=1}^{T} \left( \frac{Y_t - \mu}{\sigma}\right)^2 \right)
\end{eqnarray*}
where $T$ is the sample size. $p(\mu)$ and $p(\sigma^2)$ are priors. Here we choose the standard conjugate priors on $\mu$ and $\sigma^2$. First select the inverse gamma distribution as the prior for $\sigma^2$. The inverse gamma distribution relies on two parameters $\alpha$ and $\beta$. The density is
$$
f(\sigma^2|\alpha,\beta) = \frac{\beta^{\alpha}}{\Gamma(\alpha)} (\sigma^2)^{-\alpha-1} \exp(-\beta/\sigma^2)
$$

Therefore, the marginal density $p(\sigma^2)$ combines the prior $p(\sigma^2)$ and density $p(Y|\mu, \sigma^2)$, which yields

\begin{eqnarray*}
p(\sigma^2|\mu, Y)  &\propto& p(Y|\mu,\sigma^2) \times p(\sigma^2) \\
                    &=& \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right)^T \exp\left( -\frac{1}{2} \sum_{t=1}^{T} \left( \frac{Y_t - \mu}{\sigma}\right)^2 \right) \times \frac{\beta^{\alpha}}{\Gamma(\alpha)} (\sigma^2)^{-\alpha-1} \exp(-\beta/\sigma^2) \\
                    &\propto& (\sigma^2)^{-T/2-\alpha-1} \exp\left( -\left[\frac{1}{2}\sum_{t=1}^{T} (Y_t-\mu)^2 + \beta \right]/\sigma^2 \right) \\
                    &\propto& IG\left(\alpha+\frac{T}{2}, \beta+\frac{1}{2}\sum_{t=1}^{T}(Y_t-\mu)^2 \right)
\end{eqnarray*}

That is, given $\mu$ and $Y_t$, we are able to generate the $\sigma^2$ according to the marginal density $p(\sigma^2|\mu, Y)$. Similarly, select normal distribution as prior for $\mu$. The density is
$$
f(\mu|\theta,\delta) = \frac{1}{\sqrt{2\pi\delta^2}} \exp\left( -\frac{1}{2} \left( \frac{\mu-\theta}{\delta} \right)^2 \right)
$$
and the marginal density is
\begin{eqnarray*}
p(\mu|\sigma^2, Y)  &\propto& p(Y|\mu,\sigma^2) \times p(\mu) \\
                    &=& \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right)^T \exp\left( -\frac{1}{2} \sum_{t=1}^{T} \left( \frac{Y_t - \mu}{\sigma}\right)^2 \right) \times \frac{1}{\sqrt{2\pi\delta^2}} \exp\left( -\frac{1}{2} \left( \frac{\mu-\theta}{\delta} \right)^2 \right)
\end{eqnarray*}

To deal with $Y_t - \mu$, denote $\hat{\mu}=\left( \sum_{t=1}^T Y_t \right)/T$, and
\begin{eqnarray*}
\sum_{t=1}^T (Y_t - \mu)^2 &=&  \sum_{t=1}^T (Y_t - \hat{\mu} + \hat{\mu} - \mu)^2 \\
                           &=&  \sum_{t=1}^T (Y_t - \hat{\mu})^2 + 2(\hat{\mu}-\mu)\sum_{t=1}^T(Y_t-\hat{\mu}) + \sum_{t=1}^T(\hat{\mu} - \mu)^2 \\
                           &=&  \sum_{t=1}^T (Y_t - \hat{\mu})^2 + T(\hat{\mu}-\mu)^2
\end{eqnarray*}

Continuing on the marginal density, we have
\begin{eqnarray*}
p(\mu|\sigma^2, Y) &\propto& \exp\left(-\frac{T}{2\sigma^2}(\mu-\mu)^2-\frac{1}{2\delta^2}(\mu-\theta)^2\right) \\
                   &\propto& \exp\left(-\frac{T}{2\sigma^2}(-2\hat{\mu}\mu+\mu^2)-\frac{1}{2\delta^2}(\mu^2-2\mu\theta)\right) \\
                   &\propto& \exp\left(-\frac{1}{2\delta^{*2}} \left( \mu-\left(\frac{T\hat{\mu}}{\sigma^2} + \frac{\theta}{\delta^2}\right)\delta^{*2} \right)^2 \right) \\
                   &\propto& N\left( \left( \sum_{t=1}^T Y_t / \sigma^2 + \theta/\delta^2 \right)\delta^{*2}, \delta^{*2} \right)
\end{eqnarray*}
where $\delta^{*2} = (T/\sigma^2+1/\delta^2)^{-1}$.

Given the prior distributions, the complete MCMC method to conduct parameter estimation and statistical inference is
\begin{enumerate}
    \item initialize the parameters $\mu^{(0)}$ and $(\sigma^2)^{(0)}$;
    \item specify the parameters of the prior $\alpha, \beta, \theta, \delta$;
    \item draw $\mu^{(g+1)} \sim p(\mu|(\sigma^2)^{(g)}, Y)$;
    \item draw $(\sigma^2)^{(g+1)} \sim p(\sigma^2|\mu^{(g+1)}, Y)$;
    \item estimate parameters in $\{\mu^{(g)}, (\sigma^2)^{(g)} \}_{g=1}^{G}$
\end{enumerate}
and $G$ is the simulation size. In this paper, we select $G=2000$.

\subsection{Merton Jump Diffusion Model}
Merton's (1976) jump diffusion model assumes the (log) return process $Y_t$ as a mixture of Poisson distributed jumps and the Geometric Brownian Motion
\begin{equation}\label{merton_equation}
Y_t \equiv \log(S_{t}/S_{t-1}) = \mu + \sigma + Z_t \xi_t
\end{equation}

As shown in Equation~\ref{merton_equation}, in the additional to the Black-Scholes part, a jump process is incorporated, where $Z_t$ is the jump indictor equal to 1 with probability $\lambda$ (the jump intensity) and equal to 0 with probability $(1-\lambda)$. $\xi_t$ is a normally distributed random variable representing the jump size.

Different from the Black-Scholes model, there are two latent variables (state variables), $Z_t$ and $\xi_t$. That is, $X = \{Z_t, \xi_t\}_{t=1}^{T}$. As shown below,
\begin{eqnarray*}
Z_t &\sim&
\left\{
  \begin{array}{lc}
    1 & \textrm{with probability } \lambda \\
    0 & \textrm{with probability } (1-\lambda) \\
  \end{array}
\right. \\
\xi &\sim& N(\mu_s, \sigma_s^2)
\end{eqnarray*}

The parameter set is $\Theta=\{\mu, \sigma^2, \lambda, \mu_s, \sigma_s^2\}$, where $\mu_s$ and $\sigma_s^2$ are the parameters that define the distribution of $\xi$. The observed returns are $Y=\{r_t\}_{t=1}^T$. The object is to estimate $\Theta$ (and states $X$) conditional to the returns $Y$. Given $p(\Theta, X|Y) = p(\Theta, Z, \xi|Y)$, the marginal densities are obtained
$$
p(\Theta, X|Y) \propto p(Y|\Theta,X)p(X|\Theta)p(\Theta)
$$

Similar with Black-Scholes model, Hammersley-Clifford suggestions the following approach
\begin{enumerate}
    \item draw $\Theta_i^{(g+1)} \sim p(\Theta_i|\Theta_{i \backslash c}^{(g)} ,Z^{(g)}, \xi^{(g+1)}, Y)$;
    \item draw $Z^{(g+1)} \sim p(Z|\Theta^{(g+1)}, \xi^{(g)}, Y)$;
    \item draw $\xi^{(g+1)} \sim p(\xi|\Theta^{(g+1)}, Z^{(g+1)}, Y)$.
\end{enumerate}
where $\Theta_{i \backslash c}$ represents the parameter set without parameter $\Theta_i$. $G$ is the simulation size. In this paper, we select $G=2000$.

Defining the priors and deriving the posteriors is vital to MCMC algorithm. The density of the observed return is
\begin{eqnarray*}
p(Y|\Theta, Z, \xi) &=& \Pi_{t=1}^T p(Y_t|\Theta, Z_t, \xi_t) \\
p(Y_t|\Theta, Z_t, \xi_t) &\sim& N(\mu+\xi_tZ_t, \sigma^2) \\
p(Y|\Theta, Z, \xi) &=&  \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right)^T \exp\left( -\frac{1}{2} \sum_{t=1}^{T} \left( \frac{Y_t - \mu - Z_t \xi_t}{\sigma}\right)^2 \right)
\end{eqnarray*}

Using the conjugate priors, we assume the prior distribution of the five parameters in $\Theta$ as
\begin{eqnarray*}
\mu         &\sim& N(\theta, \delta^2) \\
\sigma^2    &\sim& IG(\alpha, \beta) \\
\mu_s       &\sim& N(\theta_s, \delta_s^2) \\
\sigma_s^2  &\sim& IG(\alpha_s, \beta_s) \\
\lambda     &\sim& B(\gamma, \eta)
\end{eqnarray*}
where $IG$ represents the inverse gamma distribution, and $B$ is the Beta distribution with density
$$
B(\gamma, \eta) = \frac{\Gamma(\gamma+\eta)}{\Gamma(\gamma)\Gamma(\eta)}\lambda^{\gamma-1}(1-\lambda)^{\eta-1}
$$

The posterior distribution of $\sigma^2$ can be derived by combining the likelihood of $Y_t$ and the prior of $\sigma^2$.
\begin{eqnarray*}
p(\sigma^2|\Theta_{\sigma^2 \backslash c}, Z_t, \xi_t, Y)  &\propto& p(Y|\Theta, Z_t, \xi_t,\sigma^2) \times p(\sigma^2) \\
                    &=& \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right)^T \exp\left( -\frac{1}{2} \sum_{t=1}^{T} \left( \frac{Y_t - \mu - Z_t \xi_t}{\sigma}\right)^2 \right) \times \frac{\beta^{\alpha}}{\Gamma(\alpha)} (\sigma^2)^{-\alpha-1} \exp(-\beta/\sigma^2) \\
                    &\propto& (\sigma^2)^{-T/2-\alpha-1} \exp\left( -\left[\frac{1}{2}\sum_{t=1}^{T} (Y_t-\mu-Z_t \xi_t)^2 + \beta \right]/\sigma^2 \right) \\
                    &\propto& IG\left(\alpha+\frac{T}{2}, \beta+\frac{1}{2}\sum_{t=1}^{T}(Y_t-\mu -Z_t \xi_t)^2 \right)
\end{eqnarray*}
which yields very similar result as the Black-Scholes model. The only difference is that the return $Y_t$ is adjusted not only by $\mu$ but also the $Z_t \xi_t$.

The posterior of $\mu$ obtains by defining $\hat{\mu}=\left[ \sum_{t=1}^T (Y_t-Z_t \xi_t) \right]/T$.
$$
\sum_{t=1}^T (Y_t - \mu - \xi_t Z_t)^2 = \sum_{t=1}^T (Y_t - \hat{\mu} - \xi_t Z_t) + T (\hat{\mu} - \mu)^2
$$

Then we yield
\begin{eqnarray*}
p(\mu|\Theta_{\mu\backslash c}, Z, \xi, Y) &\propto& p(\mu|\sigma^2, Z, \xi, Y) \\
        &=& p(Y|\mu, \sigma^2, \xi, Z) p(\mu) \\
        &=& \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right)^T \exp\left( -\frac{1}{2} \sum_{t=1}^{T} \left( \frac{Y_t - \mu - Z_t \xi_t}{\sigma}\right)^2 \right) \times \frac{1}{\sqrt{2\pi\delta^2}} \exp\left( -\frac{1}{2} \left( \frac{\mu-\theta}{\delta} \right)^2 \right) \\
        &\propto& \exp\left(-\frac{1}{2\delta^{*2}} \left( \mu-\left(\frac{T\hat{\mu}}{\sigma^2} + \frac{\theta}{\delta^2}\right)\delta^{*2} \right)^2 \right) \\
        &\propto& N\left( \left[ \sum_{t=1}^T (Y_t-\xi_t Z_t) / \sigma^2 + \theta/\delta^2 \right]\delta^{*2}, \delta^{*2} \right)
\end{eqnarray*}
where $\delta^{*2} = (T/\sigma^2+1/\delta^2)^{-1}$.

Then we drive the posteriors for $\mu_s$ and $\sigma_s^2$, and they define the jump size in the return process. Analogy to the derivation of the $\mu$ and $\sigma^2$, we yield
\begin{eqnarray*}
p(\sigma_s^2|\Theta_{\sigma_s^2 \backslash c}, Z_t, \xi_t, Y)  &\propto& p(\xi|\mu_s,\sigma_s^2) \times p(\sigma_s^2) \\
                    &=& \left( \frac{1}{\sqrt{2\pi\sigma_s^2}} \right)^T \exp\left( -\frac{1}{2} \sum_{t=1}^{T} \left( \frac{\xi_t - \mu }{\sigma_s}\right)^2 \right) \times \frac{\beta_s^{\alpha_s}}{\Gamma(\alpha_s)} (\sigma_s^2)^{-\alpha_s-1} \exp(-\beta_s/\sigma_s^2) \\
                    &\propto& IG\left(\alpha_s+\frac{T}{2}, \beta_s+\frac{1}{2}\sum_{t=1}^{T}(\xi_t-\mu_s)^2 \right)
\end{eqnarray*}

And the posterior of $\mu_s$, using similar technique, obtains
\begin{eqnarray*}
p(\mu_s|\Theta_{\mu_s \backslash c}, Z, \xi, Y) &\propto& p(\xi|\mu_s, \sigma_s^2) p(\mu_s) \\
        &\propto& N\left(\left[\frac{\sum_{t=1}^T \xi_t}{\sigma_s^2} + \frac{\theta_s}{\delta_s^2}\right]\delta_s^{*2}, \delta_s^{*2} \right)
\end{eqnarray*}
where $\delta_s^{*2}=(T/\sigma_s^2 + 1/\delta_s^2)^{-1}$.

The jump intensity $\lambda$ is conditional on the jump indicator $Z$. Then the posterior of $\lambda$ is
\begin{eqnarray*}
p(\lambda|\Theta_{\lambda \backslash c}, Z, \xi, Y) &=& p(\lambda|Z) = p(Z|\lambda)p(\lambda) \\
        &\propto& \prod_{t=1}^T p(Z_t|\lambda)p(\lambda) \\
        &=& \prod_{t=1}^T \lambda^{Z_t} (1-\lambda)^{1-Z_t} p(\lambda) \\
        &\propto& \lambda^{\sum_{t=1}^T Z_t} (1-\lambda)^{T-\sum_{t=1}^T Z_t} \lambda^{\gamma-1}(1-\lambda)^{\eta-1} \\
        &\propto& B\left(\sum_{t=1}^T Z_t + \gamma, T - \sum_{t=1}^T Z_t + \eta \right)
\end{eqnarray*}

The posteriors of the state variables, $\xi_t$ and $Z_t$, are
\begin{eqnarray*}
p(\xi_t|\Theta, Z_t, Y) &\propto& p(Y_t|\Theta, Z_t, \xi_t) p(\xi_t|\Theta) \\
    &\propto& \exp\left( -\frac{1}{2} \left( \frac{Y_t-\mu-\xi_t Z_t}{\sigma} \right)^2 - \frac{1}{2} \left(\frac{\xi_t-\mu_s}{\sigma_s}\right)^2 \right) \\
    &\propto& N(((Y_t-\mu)Z_t/\sigma^2+\mu_s/\sigma^2)\sigma_t^{*2}, \sigma_t^{*2})
\end{eqnarray*}
where $\sigma_t^{*2}=(Z_t/sigma^2+1/sigma_s^2)^{-1}$. And
\begin{eqnarray*}
p(Z_t=1|\Theta, \xi_t, Y_t) &\propto& p(Y_t|\Theta, Z_t=1, \xi_t)p(Z_t=1|\Theta) \\
    &\propto& \exp\left( -\frac{1}{2} \left( \frac{Y_t-\mu-\xi_t}{\sigma} \right)^2 \right) \lambda \\
p(Z_t=0|\Theta, \xi_t, Y_t) &\propto& p(Y_t|\Theta, Z_t=0, \xi_t)p(Z_t=0|\Theta) \\
    &\propto& \exp\left( -\frac{1}{2} \left( \frac{Y_t-\mu}{\sigma} \right)^2 \right) (1-\lambda) \\
\end{eqnarray*}
and the integrating constant is determined by insuring that the two probability ($p(Z_t=0)$ and $p(Z_t=1)$) add up to one.

The derivations of the posteriors complete the MCMC algorithm for the Merton jump diffusion model.


\section{Data and Empirical Results}
\subsection{Data}
The data used for the Merton jump diffusion is the daily return of S\&P500 index level over January 1954 to December 2015. The index level and the daily (log) return series are plotted in Figure~\ref{plot_spx}. Given the prices of the index, the log return is calculated by
$$
Y_t = \log(S_{t}/S_{t-1})
$$

\subsection{Estimation from Black-Scholes Model}

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{mu_sigma_bs.eps}
  \caption{The $\mu$ and $\sigma^2$ with Monte Carlo draws on the Markov Chain. The MCMC algorithm is based on Gibbs sampler. The simulation size is 2000. Parameter estimation and statistical inference are conducted between steps 1001 and 2000. The first 1000 iteration are in the burn-in period.}\label{mu_sigma_bs}
\end{figure}

\subsection{Estimation from Merton Jump Diffusion Model}

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{merton_mu_sigma.eps}
  \caption{The $\mu$ and $\sigma^2$ with Monte Carlo draws on the Markov Chain for the Merton jump diffusion model. The MCMC algorithm is based on Gibbs sampler. The simulation size is 2000. Parameter estimation and statistical inference are conducted between steps 1001 and 2000. The first 1000 iteration are in the burn-in period.}\label{mu_sigma_merton}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{merton_mus_sigmas_lambda.eps}
  \caption{The $\mu_s$, $\sigma_s^2$ and $\lambda$ with Monte Carlo draws on the Markov Chain for the Merton jump diffusion model. The MCMC algorithm is based on Gibbs sampler. The simulation size is 2000. Parameter estimation and statistical inference are conducted between steps 1001 and 2000. The first 1000 iteration are in the burn-in period.}\label{mus_sigmas_lambda_merton}
\end{figure}


\section{Conclusion}



%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\bibliographystyle{plain}
\bibliography{bib}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
\newpage
\section*{Appendix: Code for Black-Scholes and Merton jump diffusion models using Bayesian MCMC algorithm}
%\begin{spacing}{0.9}
\lstinputlisting[language=R]{assignment2.R}

\end{document}
\endinput
